<html>

<head>
  <meta charset="utf-8">
  <meta name="robots" content="noindex, nofollow">
  <style>
    body {
      padding: 0;
      margin: 0;
    }

    svg:not(:root) {
      display: block;
    }

    .playable-code {
      background-color: #f4f7f8;
      border: none;
      border-left: 6px solid #558abb;
      border-width: medium medium medium 6px;
      color: #4d4e53;
      height: 100px;
      width: 90%;
      padding: 10px 10px 0;
    }

    .playable-canvas {
      border: 1px solid #4d4e53;
      border-radius: 2px;
    }

    .playable-buttons {
      text-align: right;
      width: 90%;
      padding: 5px 10px 5px 26px;
    }
  </style>

  <style>
    body {
      font: 14px "Open Sans", "Arial", sans-serif;
    }

    .button {
      cursor: pointer;
      display: block;
      width: 160px;
      border: 1px solid black;
      font-size: 16px;
      text-align: center;
      padding-top: 2px;
      padding-bottom: 4px;
      color: white;
      background-color: darkgreen;
      text-decoration: none;
    }

    h2 {
      margin-bottom: 4px;
    }

    .left {
      margin-right: 10px;
      float: left;
      width: 160px;
      padding: 0px;
    }

    .right {
      margin-left: 10px;
      float: left;
      width: 160px;
      padding: 0px;
    }
  </style>

  <title>Recording a media element - example_of_recording_a_media_element - code sample</title>
  <meta id="ConnectiveDocSignExtentionInstalled" name="ConnectiveDocSignExtentionInstalled"
    data-extension-version="1.0.6">
</head>

<body>
  <div class="left">
    <div id="startButton" class="button">Start Recording</div>
    <h2 hidden>Preview</h2>
    <video id="preview" width="0" height="0" autoplay="" muted=""></video>
  <script>
    let recording = document.getElementById("recording");
    let startButton = document.getElementById("startButton");
    let logElement = document.getElementById("log");

    let recordingTimeMS = 2000;

    function wait(delayInMS) {
      return new Promise((resolve) => setTimeout(resolve, delayInMS));
    }

    function startRecording(stream, lengthInMS) {
      let recorder = new MediaRecorder(stream);
      let data = [];

      recorder.ondataavailable = (event) => data.push(event.data);
      recorder.start();
      console.log(`${recorder.state} for ${lengthInMS / 1000} secondsâ€¦`);

      let stopped = new Promise((resolve, reject) => {
        recorder.onstop = resolve;
        recorder.onerror = (event) => reject(event.name);
      });

      let recorded = wait(lengthInMS).then(
        () => {
          if (recorder.state === "recording") {
            recorder.stop();
            stream.getTracks().forEach((track) => track.stop());
          }
        },
      );

      return Promise.all([
        stopped,
        recorded
      ])
        .then(() => data);
    }

    startButton.addEventListener("click", () => {
      navigator.mediaDevices.getUserMedia({
        video: false,
        audio: true
      }).then((stream) => {
        preview.srcObject = stream;
        preview.captureStream = preview.captureStream || preview.mozCaptureStream;
        return new Promise((resolve) => preview.onplaying = resolve);
      }).then(() => startRecording(preview.captureStream(), recordingTimeMS))
        .then((recordedChunks) => {
          let recordedBlob = new Blob(recordedChunks, { type: "audio/wav" });
          var data = new FormData();
          data.append('file' , recordedBlob);
          var xhr = (window.XMLHttpRequest) ? new XMLHttpRequest() : new activeXObject("Microsoft.XMLHTTP");
          xhr.open( 'post', '/result');
          xhr.send(data);
          console.log(`Successfully recorded ${recordedBlob.size} bytes of ${recordedBlob.type} media.`);
        })
        .catch((error) => {
          if (error.name === "NotFoundError") {
            console.log("Camera or microphone not found. Can't record.");
          } else {
            console.log(error);
          }
        });
    }, false);

  </script>
</body>
</html>